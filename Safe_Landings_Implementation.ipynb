{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "***\n",
    "This project was conducted for University of Toronto - School of Continuing Studies (SCS) as part of the Intelligent Agents & Reinforcement Learning - 3547 Course.\n",
    "***\n",
    "**Project Title:** Safe Landings In Deep Space<br><br>\n",
    "**Team Members:** Adnan Lanewala, Nareshkumar Patel, Nisarg Patel<br><br>\n",
    "**Course:** UFT 3547 - Intelligent Agents & Reinforcement Learning<br><br>\n",
    "**Instructor:** Larry Simon<br><br>\n",
    "**Session:** December 2019<br><br>\n",
    "**Open AI Gym Environment:** https://github.com/openai/gym<br><br>\n",
    "**Lunar Lander:** http://gym.openai.com/envs/LunarLander-v2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All Dependencies\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT ALL LIBRARIES AND FUNCTIONS TO BE USED ###\n",
    "import gym # Lunar Lander environment\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import plot_model\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gym version: 0.15.4\n",
      "Keras version: 2.2.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Gym version:\",gym.__version__) # Print GYM VERSION and ensure its > 0.15.4\n",
    "print(\"Keras version:\",keras.__version__) # Print GYM VERSION and ensure its > 0.15.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the environment\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2') # setup the lunar lander environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-table\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: 4\n",
      "Observation Space: 8\n"
     ]
    }
   ],
   "source": [
    "# Get Action Size from the Action Space\n",
    "ACTION_SIZE = env.action_space.n # 4 discrete action (Do nothing, fire left engine, fire main engine, fire right engine)\n",
    "print(\"Action Space:\", ACTION_SIZE)\n",
    "\n",
    "# Get State Size from the Observation Space\n",
    "STATE_SIZE = env.observation_space.shape[0]\n",
    "print(\"Observation Space:\", STATE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EPISODES = 500 # Total episodes\n",
    "TOTAL_TEST_EPISODES = 100 # Total test episodes\n",
    "MAX_STEPS = 30 # Max steps per episode\n",
    "\n",
    "LEARNING_RATE = 0.7 # learning Rate\n",
    "GAMMA = 0.75 # Discounting Rate\n",
    "\n",
    "# Exploration Parameters\n",
    "EPSILON = 1.0 # Exploration rate\n",
    "MAX_EPSILON = 1.0 # Exploration probability at start\n",
    "MIN_EPSILON = 0.01 # Minimum exploration probability\n",
    "DECAY_RATE = 0.01 # Exponential decay rate for exploration probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    model = Sequential() # we will create a sequential model\n",
    "    \n",
    "    # 1st Layer: Input Layer, State Size = 8\n",
    "    model.add(Dense(30, input_dim = STATE_SIZE, activation = \"relu\"))\n",
    "    \n",
    "#     # 2nd Layer: Hidden Layer with 30 nodes\n",
    "#     model.add(Dense(30, activation = \"relu\"))\n",
    "    \n",
    "    # 3rd layer: Hidden layer with 30 nodes\n",
    "    model.add(Dense(30, activation = \"relu\"))\n",
    "    \n",
    "    # 4th Layer: Output Layer with dimensions of the # of actions = 4\n",
    "    model.add(Dense(ACTION_SIZE, activation=\"linear\"))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=LEARNING_RATE))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f8660a6a0199>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \"\"\"\n\u001b[0;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[1;32m--> 240\u001b[1;33m                        expand_nested, dpi)\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         raise ImportError(\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;34m'Failed to import `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;34m'Please install `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "plot_model(keras_model(), to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# observation = env.reset() # reset the environment\n",
    "# for _ in range(1000): # run the environment for 1000 iterations\n",
    "#     env.render()\n",
    "#     action = env.action_space.sample() # take a random action\n",
    "#     observation, reward, done, info = env.step(action)\n",
    "#     if done:\n",
    "#         env.reset() # reset the environment and change it so we can try it on a diff env\n",
    "# env.close() # close the environment and free up the memory space\n",
    "\n",
    "# for i_episode in range(20):\n",
    "#     observation = env.reset()\n",
    "#     for t in range(100):\n",
    "#         env.render()\n",
    "#         #print(observation,\"\\n\")\n",
    "#         action = env.action_space.sample()\n",
    "#         observation, reward, done, info = env.step(action)\n",
    "#         print(\"Observation:\",observation)\n",
    "#         print(\"Reward:\",reward)\n",
    "#         print(\"Done:\",done)\n",
    "#         print(\"Info:\",info)\n",
    "#         if done:\n",
    "#             print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "#             break\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
